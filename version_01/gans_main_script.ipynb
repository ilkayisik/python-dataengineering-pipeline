{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5237e33c-9f17-4dc7-8e5f-8110b176d935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import api keys\n",
    "from api_keys import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf89b69-98fd-44ba-920e-936dff6b21df",
   "metadata": {},
   "source": [
    "## Flights API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118559ad-79e4-4155-aa82-a4193204bf33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "airport_icoa = \"EDDB\"\n",
    "to_local_time = datetime.now().strftime('%Y-%m-%dT%H:00')\n",
    "from_local_time = (datetime.now() + timedelta(hours=9)).strftime('%Y-%m-%dT%H:00')\n",
    "url = f\"https://aerodatabox.p.rapidapi.com/flights/airports/icao/{airport_icoa}/{to_local_time}/{from_local_time}\"\n",
    "\n",
    "import requests\n",
    "\n",
    "querystring = {\"withLeg\":\"true\",\"withCancelled\":\"true\",\"withCodeshared\":\"true\",\"withCargo\":\"true\",\"withPrivate\":\"false\",\"withLocation\":\"false\"}\n",
    "\n",
    "headers = {\n",
    "    'x-rapidapi-host': \"aerodatabox.p.rapidapi.com\",\n",
    "    'x-rapidapi-key': flight_api_key\n",
    "    }\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "\n",
    "from IPython.display import JSON\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7089cd61-639d-455b-9333-b524fc8fca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Option 1\n",
    "arrivals_berlin = response.json()['arrivals']\n",
    "\n",
    "def get_flight_info(flight_json):\n",
    "    # terminal\n",
    "    try: terminal = flight_json['arrival']['terminal']\n",
    "    except: terminal = None\n",
    "    # aircraft\n",
    "    try: aircraft = flight_json['aircraft']['model']\n",
    "    except: aircraft = None\n",
    "\n",
    "    return {\n",
    "        'dep_airport':flight_json['departure']['airport']['name'],\n",
    "        'sched_arr_loc_time':flight_json['arrival']['scheduledTimeLocal'],\n",
    "        'terminal':terminal,\n",
    "        'status':flight_json['status'],\n",
    "        'aircraft':aircraft,\n",
    "        'icao_code':airport_icoa\n",
    "    }\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "# [get_flight_info(flight) for flight in arrivals_berlin]\n",
    "arrivals_berlin = pd.DataFrame([get_flight_info(flight) for flight in arrivals_berlin])\n",
    "arrivals_berlin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18faf618-b292-4ab6-a818-d4efb73dd186",
   "metadata": {},
   "source": [
    "## Wheather API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3ea2a3-6efd-4c19-8afa-cb1800fdaf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "city = \"Berlin\"\n",
    "country = \"DE\"\n",
    "response = requests.get(f'http://api.openweathermap.org/data/2.5/forecast/?q={city},{country}&appid={OWM_key}&units=metric&lang=en')\n",
    "from IPython.display import JSON\n",
    "\n",
    "# JSON(response.json())\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38359d0d-25a6-4a76-8a4f-2469becd62db",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_api = response.json()['list']\n",
    "# look for the fields that could be relevant: \n",
    "# better field descriptions https://www.weatherbit.io/api/weather-forecast-5-day\n",
    "\n",
    "weather_info = []\n",
    "\n",
    "# datetime, temperature, wind, prob_perc, rain_qty, snow = [], [], [], [], [], []\n",
    "for forecast_3h in forecast_api: \n",
    "    weather_hour = {}\n",
    "    # datetime utc\n",
    "    weather_hour['datetime'] = forecast_3h['dt_txt']\n",
    "    # temperature \n",
    "    weather_hour['temperature'] = forecast_3h['main']['temp']\n",
    "    # wind\n",
    "    weather_hour['wind'] = forecast_3h['wind']['speed']\n",
    "    # probability precipitation \n",
    "    try: weather_hour['prob_perc'] = float(forecast_3h['pop'])\n",
    "    except: weather_hour['prob_perc'] = 0\n",
    "    # rain\n",
    "    try: weather_hour['rain_qty'] = float(forecast_3h['rain']['3h'])\n",
    "    except: weather_hour['rain_qty'] = 0\n",
    "    # wind \n",
    "    try: weather_hour['snow'] = float(forecast_3h['snow']['3h'])\n",
    "    except: weather_hour['snow'] = 0\n",
    "    weather_hour['municipality_iso_country'] = city + ',' + country\n",
    "    weather_info.append(weather_hour)\n",
    "    \n",
    "weather_data = pd.DataFrame(weather_info)\n",
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223ced61-266e-4357-98da-39d8913d90d8",
   "metadata": {},
   "source": [
    "## Population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39886116-8a42-4bf0-aa97-375682413e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "cities = ['Berlin','Paris','Amsterdam','Barcelona','Rome','Lisbon','Prague','Vienna','Madrid']\n",
    "\n",
    "def City_info(soup):\n",
    "    \n",
    "    ret_dict = {}\n",
    "    ret_dict['city'] = soup.h1.get_text()\n",
    "    \n",
    "    if soup.select_one('.mergedrow:-soup-contains(\"Mayor\")>.infobox-label') != None:\n",
    "        i = soup.select_one('.mergedrow:-soup-contains(\"Mayor\")>.infobox-label')\n",
    "        mayor_name_html = i.find_next_sibling()\n",
    "        mayor_name = unicodedata.normalize('NFKD',mayor_name_html.get_text())\n",
    "        ret_dict['mayor']  = mayor_name\n",
    "    \n",
    "    if soup.select_one('.mergedrow:-soup-contains(\"City\")>.infobox-label') != None:\n",
    "        j =  soup.select_one('.mergedrow:-soup-contains(\"City\")>.infobox-label')\n",
    "        area = j.find_next_sibling('td').get_text()\n",
    "        ret_dict['city_size'] = unicodedata.normalize('NFKD',area)\n",
    "\n",
    "    if soup.select_one('.mergedtoprow:-soup-contains(\"Elevation\")>.infobox-data') != None:\n",
    "        k = soup.select_one('.mergedtoprow:-soup-contains(\"Elevation\")>.infobox-data')\n",
    "        elevation_html = k.get_text()\n",
    "        ret_dict['elevation'] = unicodedata.normalize('NFKD',elevation_html)\n",
    "    \n",
    "    if soup.select_one('.mergedtoprow:-soup-contains(\"Population\")') != None:\n",
    "        l = soup.select_one('.mergedtoprow:-soup-contains(\"Population\")')\n",
    "        c_pop = l.findNext('td').get_text()\n",
    "        ret_dict['city_population'] = c_pop\n",
    "    \n",
    "    if soup.select_one('.infobox-label>[title^=Urban]') != None:\n",
    "        m = soup.select_one('.infobox-label>[title^=Urban]')\n",
    "        u_pop = m.findNext('td')\n",
    "        ret_dict['urban_population'] = u_pop.get_text()\n",
    "\n",
    "    if soup.select_one('.infobox-label>[title^=Metro]') != None:\n",
    "        n = soup.select_one('.infobox-label>[title^=Metro]')\n",
    "        m_pop = n.findNext('td')\n",
    "        ret_dict['metro_population'] = m_pop.get_text()\n",
    "    \n",
    "    if soup.select_one('.latitude') != None:\n",
    "        o = soup.select_one('.latitude')\n",
    "        ret_dict['lat'] = o.get_text()\n",
    "\n",
    "    if soup.select_one('.longitude') != None:    \n",
    "        p = soup.select_one('.longitude')\n",
    "        ret_dict['long'] = p.get_text()\n",
    "    \n",
    "    return ret_dict\n",
    "\n",
    "list_of_city_info = []\n",
    "for city in cities:\n",
    "    url = 'https://en.wikipedia.org/wiki/{}'.format(city)\n",
    "    web = requests.get(url,'html.parser')\n",
    "    soup = bs(web.content)\n",
    "    list_of_city_info.append(City_info(soup))\n",
    "df_cities = pd.DataFrame(list_of_city_info)\n",
    "# df_cities = df_cities.set_index('city')\n",
    "df_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecdf895",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cities['municipality_iso_country'] = [\n",
    "    'Berlin,DE',\n",
    "    'Paris,FR',\n",
    "    'Amsterdam,NL',\n",
    "    'Barcelona,ES',\n",
    "    'Rome,IT',\n",
    "    'Lisbon,PT',\n",
    "    'Prague,CZE',\n",
    "    'Vienna,AT',\n",
    "    'Madrid,ES'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c8081b-545c-4558-981b-93581aa07309",
   "metadata": {},
   "source": [
    "## Airports data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b388c0-a605-4234-a415-ee16da024587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "airports_cities = (\n",
    "pd.read_csv('airports.csv')\n",
    "    .query('type == \"large_airport\"')\n",
    "    .filter(['name','latitude_deg','longitude_deg','iso_country','iso_region','municipality','gps_code','iata_code'])\n",
    "    .rename(columns={'gps_code':'icao_code'})\n",
    "    .assign(municipality_iso_country = lambda x: x['municipality'] + ',' + x['iso_country'])\n",
    ")\n",
    "airports_cities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ad5947-6172-43fc-9f0a-3789a4b1fb8e",
   "metadata": {},
   "source": [
    "## Check the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71d669a-9948-4d1a-bbec-54500a880c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrivals_berlin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb0d69c-c8e7-4169-aaaf-e12b58e7e5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5386a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4a24c4-40dc-4e58-9f98-acaad796c180",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdfdef7-1cd0-429d-892e-3bdfc1083a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# airports_cities.merge(arrivals_berlin, on='icao_code', how='inner').merge(weather_data, on='municipality_iso_country', how='inner').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78660346-6ce7-41a5-80cc-0e018825e54e",
   "metadata": {},
   "source": [
    "## Update data into database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23a10c5",
   "metadata": {},
   "source": [
    "First run this code in mysql:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601a2a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DROP DATABASE gans;\n",
    "CREATE DATABASE IF NOT EXISTS gans; \n",
    "USE gans;\n",
    "\n",
    "DROP TABLE IF EXISTS cities;\n",
    "CREATE TABLE IF NOT EXISTS cities (\n",
    "    city VARCHAR(200),\n",
    "    mayor TEXT,\n",
    "    city_size TEXT, \n",
    "    elevation TEXT, \n",
    "    city_population TEXT, \n",
    "    urban_population TEXT, \n",
    "    metro_population TEXT, \n",
    "    latitude TEXT, \n",
    "    longitude TEXT, \n",
    "\tmunicipality_iso_country varchar(200),\n",
    "    PRIMARY KEY(municipality_iso_country)\n",
    "); \n",
    "\n",
    "DROP TABLE IF EXISTS airports;\n",
    "CREATE TABLE IF NOT EXISTS airports(\n",
    "\tname text, \n",
    "    latitude_deg float, \n",
    "    longitude_deg float, \n",
    "    iso_country varchar(10), \n",
    "    iso_region varchar(10),\n",
    "    municipality text, \n",
    "    icao_code varchar(4), \n",
    "    iata_code varchar(6), \n",
    "    municipality_iso_country varchar(200),\n",
    "    primary key(icao_code)\n",
    "    -- foreign key (municipality_iso_country) references cities(municipality_iso_country)\n",
    ");\n",
    "\n",
    "\n",
    "DROP TABLE IF EXISTS weather; \n",
    "CREATE TABLE IF NOT EXISTS weather (\n",
    "\tweather_id int auto_increment, \n",
    "    datetime datetime, \n",
    "    temperature float, \n",
    "    wind float, \n",
    "    prob_perc float, \n",
    "    rain_qty float, \n",
    "    snow integer, \n",
    "    municipality_iso_country varchar(200),\n",
    "    primary key(weather_id),\n",
    "    foreign key (municipality_iso_country) references cities(municipality_iso_country)\n",
    ");\n",
    "\n",
    "DROP TABLE IF EXISTS arrivals; \n",
    "CREATE TABLE IF NOT EXISTS arrivals(\n",
    "\tarrivals_id int auto_increment, \n",
    "    dep_airport text, \n",
    "    sched_arr_loc_time datetime, \n",
    "    terminal text, \n",
    "    status text, \n",
    "\taircraft text, \n",
    "    icao_code varchar(4),\n",
    "    primary key (arrivals_id)\n",
    "    -- foreign key (icao_code) references airports(icao_code)\n",
    ");\n",
    "\n",
    "\n",
    "USE gans;\n",
    "SELECT * FROM arrivals;\n",
    "SELECT * FROM weather;\n",
    "SELECT * FROM cities;\n",
    "SELECT * FROM airports;\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4064d5d-de67-4a36-86a7-3fdc271e00a1",
   "metadata": {},
   "source": [
    "### `sqlalchemy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7501b136-8223-4e30-8c3c-96d1560fd288",
   "metadata": {},
   "source": [
    "#### Establish the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2ce62b-8fe9-42cc-8a9b-bad25fc60252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357dd087",
   "metadata": {},
   "source": [
    "## If you are running locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eab7e9d-5994-48c9-9111-711ce8d1b019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my local database\n",
    "schema=\"gans\"\n",
    "host=\"127.0.0.1\"\n",
    "user=\"root\"\n",
    "password=\"password\"\n",
    "port=3306\n",
    "con = f'mysql+pymysql://{user}:{password}@{host}:{port}/{schema}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3b124a",
   "metadata": {},
   "source": [
    "## If you are running on the AWS instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9951e1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my AWS instance\n",
    "schema=\"gans\"\n",
    "host=\"\"\n",
    "user=\"admin\"\n",
    "password=\"password\"\n",
    "port=3306\n",
    "con = f'mysql+pymysql://{user}:{password}@{host}:{port}/{schema}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce7200a-3763-4112-9ec7-0af3709cd871",
   "metadata": {},
   "source": [
    "#### Update the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5027da",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "df_cities\n",
    "    # .dropna()\n",
    "    .rename(\n",
    "        columns={\n",
    "            'lat':'latitude',\n",
    "            'long':'longitude'\n",
    "            }\n",
    "        )\n",
    "    .to_sql('cities', con=con, if_exists='append', index=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891b2faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "airports_cities\n",
    "    .dropna()\n",
    "    .to_sql('airports', if_exists='append', con=con, index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fe8ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    weather_data\n",
    "    .assign(datetime = lambda x: pd.to_datetime(x['datetime']))\n",
    "    .to_sql('weather', if_exists='append', con=con, index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e438b5-e367-475b-b609-1813f60f8a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "(\n",
    "arrivals_berlin\n",
    "    .replace({np.nan},'unknown')\n",
    "    .assign(sched_arr_loc_time = lambda x: pd.to_datetime(x['sched_arr_loc_time']))\n",
    "    .to_sql('arrivals', if_exists='append', con=con, index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('WBS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fcc9d8ba76f1a84e8c881b612cc0c7cddd952f7c20275e7661e3d93778145587"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
